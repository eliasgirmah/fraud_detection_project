{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac3a9014-a934-485f-989b-bf2f70af88bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card Data - Head:\n",
      "    Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10       V11       V12       V13       V14  \\\n",
      "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
      "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
      "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
      "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
      "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
      "\n",
      "        V15       V16       V17       V18       V19       V20       V21  \\\n",
      "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
      "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
      "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
      "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
      "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
      "\n",
      "        V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
      "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
      "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
      "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
      "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
      "\n",
      "   Amount  Class  \n",
      "0  149.62      0  \n",
      "1    2.69      0  \n",
      "2  378.66      0  \n",
      "3  123.50      0  \n",
      "4   69.99      0  \n",
      "\n",
      "Fraud Data - Head:\n",
      "                  signup_time        purchase_time  purchase_value  \\\n",
      "user_id                                                             \n",
      "22058    2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
      "333320   2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
      "1359     2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
      "150084   2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
      "221365   2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
      "\n",
      "             device_id sex  age    ip_address  class  transaction_hour  \\\n",
      "user_id                                                                  \n",
      "22058    QVPSPJUOCKZAR   M   39  7.327584e+08      0                 2   \n",
      "333320   EOGFQPIZPYXFZ   F   53  3.503114e+08      0                 1   \n",
      "1359     YSSKYOSJHPPLJ   M   53  2.621474e+09      1                18   \n",
      "150084   ATGTXKYKUDUQN   M   41  3.840542e+09      0                13   \n",
      "221365   NAUITBZFJKHWW   M   45  4.155831e+08      0                18   \n",
      "\n",
      "         transaction_day_of_week  transaction_frequency  browser_FireFox  \\\n",
      "user_id                                                                    \n",
      "22058                          5                      1            False   \n",
      "333320                         0                      1            False   \n",
      "1359                           3                      1            False   \n",
      "150084                         0                      1            False   \n",
      "221365                         2                      1            False   \n",
      "\n",
      "         browser_IE  browser_Opera  browser_Safari  source_Direct  source_SEO  \\\n",
      "user_id                                                                         \n",
      "22058         False          False           False          False        True   \n",
      "333320        False          False           False          False       False   \n",
      "1359          False           True           False          False        True   \n",
      "150084        False          False            True          False        True   \n",
      "221365        False          False            True          False       False   \n",
      "\n",
      "         purchase_value_scaled  \n",
      "user_id                         \n",
      "22058                -0.160204  \n",
      "333320               -1.142592  \n",
      "1359                 -1.197169  \n",
      "150084                0.385567  \n",
      "221365                0.112681  \n",
      "\n",
      "Credit Card Data Shape: (284807, 31)\n",
      "Fraud Data Shape: (151112, 18)\n",
      "\n",
      "Missing Values in Credit Card Data:\n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Fraud Data:\n",
      " signup_time                0\n",
      "purchase_time              0\n",
      "purchase_value             0\n",
      "device_id                  0\n",
      "sex                        0\n",
      "age                        0\n",
      "ip_address                 0\n",
      "class                      0\n",
      "transaction_hour           0\n",
      "transaction_day_of_week    0\n",
      "transaction_frequency      0\n",
      "browser_FireFox            0\n",
      "browser_IE                 0\n",
      "browser_Opera              0\n",
      "browser_Safari             0\n",
      "source_Direct              0\n",
      "source_SEO                 0\n",
      "purchase_value_scaled      0\n",
      "dtype: int64\n",
      "\n",
      "Credit Card Data Types:\n",
      " Time      float64\n",
      "V1        float64\n",
      "V2        float64\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5        float64\n",
      "V6        float64\n",
      "V7        float64\n",
      "V8        float64\n",
      "V9        float64\n",
      "V10       float64\n",
      "V11       float64\n",
      "V12       float64\n",
      "V13       float64\n",
      "V14       float64\n",
      "V15       float64\n",
      "V16       float64\n",
      "V17       float64\n",
      "V18       float64\n",
      "V19       float64\n",
      "V20       float64\n",
      "V21       float64\n",
      "V22       float64\n",
      "V23       float64\n",
      "V24       float64\n",
      "V25       float64\n",
      "V26       float64\n",
      "V27       float64\n",
      "V28       float64\n",
      "Amount    float64\n",
      "Class       int64\n",
      "dtype: object\n",
      "\n",
      "Fraud Data Types:\n",
      " signup_time                 object\n",
      "purchase_time               object\n",
      "purchase_value               int64\n",
      "device_id                   object\n",
      "sex                         object\n",
      "age                          int64\n",
      "ip_address                 float64\n",
      "class                        int64\n",
      "transaction_hour             int64\n",
      "transaction_day_of_week      int64\n",
      "transaction_frequency        int64\n",
      "browser_FireFox               bool\n",
      "browser_IE                    bool\n",
      "browser_Opera                 bool\n",
      "browser_Safari                bool\n",
      "source_Direct                 bool\n",
      "source_SEO                    bool\n",
      "purchase_value_scaled      float64\n",
      "dtype: object\n",
      "\n",
      "Duplicate Rows in Credit Card Data: 1081\n",
      "Duplicate Rows in Fraud Data: 0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "# Add the 'scripts' directory to the Python path for module imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "# Set max rows and columns to display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Import the SetupLogger and LoadData classes\n",
    "from loggers import SetupLogger\n",
    "from load_data import LoadData\n",
    "\n",
    "# Initialize logger\n",
    "logger = SetupLogger(log_file='../logs/notebooks.log').get_logger()\n",
    "\n",
    "# Load datasets\n",
    "load_fraud = LoadData('../data/fraud_data_processed.csv', logger=logger)\n",
    "load_credit = LoadData('../data/creditcard.csv', logger=logger)\n",
    "\n",
    "# Load and explore the datasets\n",
    "fraud_data = load_fraud.load_dataset().set_index('user_id')\n",
    "credit_data = load_credit.load_dataset()\n",
    "\n",
    "# Display first few rows of both datasets\n",
    "print(\"Credit Card Data - Head:\\n\", credit_data.head())\n",
    "print(\"\\nFraud Data - Head:\\n\", fraud_data.head())\n",
    "\n",
    "# Check dataset shapes\n",
    "print(\"\\nCredit Card Data Shape:\", credit_data.shape)\n",
    "print(\"Fraud Data Shape:\", fraud_data.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Credit Card Data:\\n\", credit_data.isnull().sum())\n",
    "print(\"\\nMissing Values in Fraud Data:\\n\", fraud_data.isnull().sum())\n",
    "\n",
    "# Check for data types\n",
    "print(\"\\nCredit Card Data Types:\\n\", credit_data.dtypes)\n",
    "print(\"\\nFraud Data Types:\\n\", fraud_data.dtypes)\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nDuplicate Rows in Credit Card Data:\", credit_data.duplicated().sum())\n",
    "print(\"Duplicate Rows in Fraud Data:\", fraud_data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35bfaed4-577f-4a1c-b71f-e20a152a1e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows in Credit Card Data: 1081\n",
      "Remaining Rows after removing duplicates: 283726\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicate Rows in Credit Card Data: {credit_data.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates\n",
    "credit_data = credit_data.drop_duplicates()\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Remaining Rows after removing duplicates: {len(credit_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45698db2-ec66-4926-b282-80bde65d5fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Credit Card Data:\n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Fraud Data:\n",
      " signup_time                0\n",
      "purchase_time              0\n",
      "purchase_value             0\n",
      "device_id                  0\n",
      "sex                        0\n",
      "age                        0\n",
      "ip_address                 0\n",
      "class                      0\n",
      "transaction_hour           0\n",
      "transaction_day_of_week    0\n",
      "transaction_frequency      0\n",
      "browser_FireFox            0\n",
      "browser_IE                 0\n",
      "browser_Opera              0\n",
      "browser_Safari             0\n",
      "source_Direct              0\n",
      "source_SEO                 0\n",
      "purchase_value_scaled      0\n",
      "dtype: int64\n",
      "\n",
      "Remaining Missing Values in Credit Card Data:\n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n",
      "Remaining Missing Values in Fraud Data:\n",
      " signup_time                0\n",
      "purchase_time              0\n",
      "purchase_value             0\n",
      "device_id                  0\n",
      "sex                        0\n",
      "age                        0\n",
      "ip_address                 0\n",
      "class                      0\n",
      "transaction_hour           0\n",
      "transaction_day_of_week    0\n",
      "transaction_frequency      0\n",
      "browser_FireFox            0\n",
      "browser_IE                 0\n",
      "browser_Opera              0\n",
      "browser_Safari             0\n",
      "source_Direct              0\n",
      "source_SEO                 0\n",
      "purchase_value_scaled      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values or drop them based on the dataset characteristics\n",
    "\n",
    "# Credit Card Data\n",
    "print(\"\\nMissing Values in Credit Card Data:\\n\", credit_data.isnull().sum())\n",
    "\n",
    "# Fraud Data\n",
    "print(\"\\nMissing Values in Fraud Data:\\n\", fraud_data.isnull().sum())\n",
    "\n",
    "# Example: Dropping rows with missing values (modify this to impute values if needed)\n",
    "credit_data = credit_data.dropna()  # Drop rows with missing values in credit card data\n",
    "fraud_data = fraud_data.dropna()    # Drop rows with missing values in fraud data\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nRemaining Missing Values in Credit Card Data:\\n\", credit_data.isnull().sum())\n",
    "print(\"\\nRemaining Missing Values in Fraud Data:\\n\", fraud_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6805449-331e-4a5e-a599-afaed19adca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>transaction_hour</th>\n",
       "      <th>transaction_day_of_week</th>\n",
       "      <th>transaction_frequency</th>\n",
       "      <th>browser_FireFox</th>\n",
       "      <th>browser_IE</th>\n",
       "      <th>browser_Opera</th>\n",
       "      <th>browser_Safari</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>source_SEO</th>\n",
       "      <th>purchase_value_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22058</th>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.160204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333320</th>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.142592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.197169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150084</th>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.385567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221365</th>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.112681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 signup_time        purchase_time  purchase_value  \\\n",
       "user_id                                                             \n",
       "22058    2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "333320   2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "1359     2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "150084   2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "221365   2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "             device_id sex  age    ip_address  class  transaction_hour  \\\n",
       "user_id                                                                  \n",
       "22058    QVPSPJUOCKZAR   M   39  7.327584e+08      0                 2   \n",
       "333320   EOGFQPIZPYXFZ   F   53  3.503114e+08      0                 1   \n",
       "1359     YSSKYOSJHPPLJ   M   53  2.621474e+09      1                18   \n",
       "150084   ATGTXKYKUDUQN   M   41  3.840542e+09      0                13   \n",
       "221365   NAUITBZFJKHWW   M   45  4.155831e+08      0                18   \n",
       "\n",
       "         transaction_day_of_week  transaction_frequency  browser_FireFox  \\\n",
       "user_id                                                                    \n",
       "22058                          5                      1            False   \n",
       "333320                         0                      1            False   \n",
       "1359                           3                      1            False   \n",
       "150084                         0                      1            False   \n",
       "221365                         2                      1            False   \n",
       "\n",
       "         browser_IE  browser_Opera  browser_Safari  source_Direct  source_SEO  \\\n",
       "user_id                                                                         \n",
       "22058         False          False           False          False        True   \n",
       "333320        False          False           False          False       False   \n",
       "1359          False           True           False          False        True   \n",
       "150084        False          False            True          False        True   \n",
       "221365        False          False            True          False       False   \n",
       "\n",
       "         purchase_value_scaled  \n",
       "user_id                         \n",
       "22058                -0.160204  \n",
       "333320               -1.142592  \n",
       "1359                 -1.197169  \n",
       "150084                0.385567  \n",
       "221365                0.112681  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf5c9263-7d8b-4141-ad69-bf1272112ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully.\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import DataPreparation\n",
    "# Assuming df_creditcard is the DataFrame for the credit card dataset\n",
    "_creditcard = DataPreparation(credit_data, target_column='Class')\n",
    "_creditcard.train_test_split(test_size=0.2, random_state=42)\n",
    "\n",
    "# Retrieving the train and test sets\n",
    "X_train_cc, X_test_cc, y_train_cc, y_test_cc = _creditcard.get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9312f47-1e9d-4a91-b132-accee5fbe11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_fraud is the DataFrame for the fraud dataset\n",
    "_fraud = DataPreparation(fraud_data, target_column='class')\n",
    "_fraud.train_test_split(test_size=0.2, random_state=42)\n",
    "\n",
    "# Retrieving the train and test sets\n",
    "X_train_fd, X_test_fd, y_train_fd, y_test_fd = _fraud.get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5f275e5-c249-48b8-a263-c03cdc7d3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Disable CUDA\n",
    "\n",
    "# Import the class\n",
    "from model_pipeline import ModelPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f8c9405-3b78-4104-b70c-abe07c3fe47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully.\n",
      "Data split into training and testing sets successfully.\n",
      "Tuning hyperparameters for Random Forest...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-02-18 22:32:33'\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-01-05 06:37:15'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 214\u001b[0m\n\u001b[0;32m    211\u001b[0m model_pipeline \u001b[38;5;241m=\u001b[39m ModelPipeline(X_train_fd, X_test_fd, y_train_fd, y_test_fd)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# Train and evaluate\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m best_model, best_model_name \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mtrain_and_evaluate()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Get results\u001b[39;00m\n\u001b[0;32m    217\u001b[0m results, predictions \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mget_results()\n",
      "Cell \u001b[1;32mIn[60], line 98\u001b[0m, in \u001b[0;36mModelPipeline.train_and_evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Trains and evaluates all models in the models dictionary, logs results using MLflow.\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_models()  \u001b[38;5;66;03m# Add the selected models\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameter_tuning()  \u001b[38;5;66;03m# Call hyperparameter tuning first\u001b[39;00m\n\u001b[0;32m    100\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    101\u001b[0m best_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[60], line 89\u001b[0m, in \u001b[0;36mModelPipeline.hyperparameter_tuning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     77\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m     78\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[0;32m     79\u001b[0m ])\n\u001b[0;32m     81\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     82\u001b[0m     pipeline,\n\u001b[0;32m     83\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grids[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     87\u001b[0m )\n\u001b[1;32m---> 89\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m     90\u001b[0m best_models[name] \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m best parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-02-18 22:32:33'\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-01-05 06:37:15'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6d57106-f28c-48c8-aee3-c800f0ebd1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                      int64\n",
      "signup_time                 object\n",
      "purchase_time               object\n",
      "purchase_value               int64\n",
      "device_id                   object\n",
      "sex                         object\n",
      "age                          int64\n",
      "ip_address                 float64\n",
      "transaction_hour             int64\n",
      "transaction_day_of_week      int64\n",
      "transaction_frequency        int64\n",
      "browser_FireFox               bool\n",
      "browser_IE                    bool\n",
      "browser_Opera                 bool\n",
      "browser_Safari                bool\n",
      "source_Direct                 bool\n",
      "source_SEO                    bool\n",
      "purchase_value_scaled      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train_fd.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d80f117-fa86-46d7-b46d-6ee487a47ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                             int64\n",
      "signup_time                datetime64[ns]\n",
      "purchase_time              datetime64[ns]\n",
      "purchase_value                      int64\n",
      "device_id                          object\n",
      "sex                                object\n",
      "age                                 int64\n",
      "ip_address                        float64\n",
      "class                               int64\n",
      "transaction_hour                    int64\n",
      "transaction_day_of_week             int64\n",
      "transaction_frequency               int64\n",
      "browser_FireFox                      bool\n",
      "browser_IE                           bool\n",
      "browser_Opera                        bool\n",
      "browser_Safari                       bool\n",
      "source_Direct                        bool\n",
      "source_SEO                           bool\n",
      "purchase_value_scaled             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Convert 'signup_time' and 'purchase_time' to datetime objects\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "\n",
    "# Optional: Check the data types to confirm conversion\n",
    "print(fraud_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a96eae01-921c-4e5c-a107-75dcdd794e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully.\n",
      "Data split into training and testing sets successfully.\n",
      "Tuning hyperparameters for Random Forest...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-02-18 22:32:33'\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-01-05 06:37:15'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 214\u001b[0m\n\u001b[0;32m    211\u001b[0m model_pipeline \u001b[38;5;241m=\u001b[39m ModelPipeline(X_train_fd, X_test_fd, y_train_fd, y_test_fd)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# Train and evaluate\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m best_model, best_model_name \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mtrain_and_evaluate()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Get results\u001b[39;00m\n\u001b[0;32m    217\u001b[0m results, predictions \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mget_results()\n",
      "Cell \u001b[1;32mIn[66], line 98\u001b[0m, in \u001b[0;36mModelPipeline.train_and_evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Trains and evaluates all models in the models dictionary, logs results using MLflow.\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_models()  \u001b[38;5;66;03m# Add the selected models\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameter_tuning()  \u001b[38;5;66;03m# Call hyperparameter tuning first\u001b[39;00m\n\u001b[0;32m    100\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    101\u001b[0m best_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[66], line 89\u001b[0m, in \u001b[0;36mModelPipeline.hyperparameter_tuning\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     77\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m     78\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[0;32m     79\u001b[0m ])\n\u001b[0;32m     81\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     82\u001b[0m     pipeline,\n\u001b[0;32m     83\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grids[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     87\u001b[0m )\n\u001b[1;32m---> 89\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m     90\u001b[0m best_models[name] \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m best parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-02-18 22:32:33'\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n        ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: '2015-01-05 06:37:15'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, Flatten, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras\n",
    "import time\n",
    "\n",
    "class ModelPipeline:\n",
    "    \"\"\"\n",
    "    A class for building a machine learning pipeline for model selection, training, and evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.models = {}\n",
    "        self.performance_metrics = {}\n",
    "        self.y_probs = {}\n",
    "        \n",
    "    def add_models(self):\n",
    "        \"\"\"Adds selected models to the models dictionary for evaluation.\"\"\"\n",
    "        self.models['Random Forest'] = RandomForestClassifier()\n",
    "        self.models['Gradient Boosting'] = GradientBoostingClassifier()\n",
    "        self.models['LSTM'] = self.build_lstm_model()\n",
    "        self.models['CNN'] = self.build_cnn_model()\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        \"\"\"Builds an LSTM model.\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(self.X_train.shape[1], 1)))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def build_cnn_model(self):\n",
    "        \"\"\"Builds a CNN model.\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(self.X_train.shape[1], 1)))\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def hyperparameter_tuning(self):\n",
    "        \"\"\"Performs hyperparameter tuning for each selected model using GridSearchCV.\"\"\"\n",
    "        param_grids = {\n",
    "            'Random Forest': {\n",
    "                'classifier__n_estimators': [50, 100],\n",
    "                'classifier__max_depth': [None, 5, 10]\n",
    "            },\n",
    "            'Gradient Boosting': {\n",
    "                'classifier__learning_rate': [0.01, 0.1],\n",
    "                'classifier__n_estimators': [50, 100]\n",
    "            },\n",
    "        }\n",
    "\n",
    "        best_models = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            if name in ['LSTM', 'CNN']:\n",
    "                continue  # Skip hyperparameter tuning for LSTM and CNN\n",
    "\n",
    "            print(f\"Tuning hyperparameters for {name}...\")\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', model)\n",
    "            ])\n",
    "\n",
    "            search = GridSearchCV(\n",
    "                pipeline,\n",
    "                param_grid=param_grids[name],\n",
    "                cv=3,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            search.fit(self.X_train, self.y_train)\n",
    "            best_models[name] = search.best_estimator_\n",
    "            print(f\"{name} best parameters: {search.best_params_}\")\n",
    "\n",
    "        self.models.update(best_models)\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        \"\"\"Trains and evaluates all models in the models dictionary, logs results using MLflow.\"\"\"\n",
    "        self.add_models()  # Add the selected models\n",
    "        self.hyperparameter_tuning()  # Call hyperparameter tuning first\n",
    "\n",
    "        best_model = None\n",
    "        best_model_name = \"\"\n",
    "        best_score = 0\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            with mlflow.start_run(run_name=name):\n",
    "                start_time = time.time()\n",
    "                if name in ['LSTM', 'CNN']:\n",
    "                    # Reshape the data for LSTM and CNN\n",
    "                    X_train_reshaped = self.X_train.values.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
    "                    X_test_reshaped = self.X_test.values.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
    "\n",
    "                    model.fit(X_train_reshaped, self.y_train, epochs=5, batch_size=32, verbose=0)\n",
    "                    y_prob = model.predict(X_test_reshaped)\n",
    "                    y_pred = (y_prob > 0.5).astype(\"int32\")\n",
    "                    y_prob = y_prob.flatten()\n",
    "\n",
    "                else:\n",
    "                    model.fit(self.X_train, self.y_train)\n",
    "                    y_pred = model.predict(self.X_test)\n",
    "                    y_prob = model.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "                end_time = time.time()\n",
    "                training_duration = end_time - start_time\n",
    "                print(f\"{name} took {training_duration:.2f} seconds to train\")\n",
    "\n",
    "                self.y_probs[name] = y_prob\n",
    "\n",
    "                # Log metrics\n",
    "                accuracy = accuracy_score(self.y_test, y_pred)\n",
    "                precision = precision_score(self.y_test, y_pred)\n",
    "                recall = recall_score(self.y_test, y_pred)\n",
    "                f1 = f1_score(self.y_test, y_pred)\n",
    "                roc_auc = roc_auc_score(self.y_test, y_prob)\n",
    "\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_metric(\"precision\", precision)\n",
    "                mlflow.log_metric(\"recall\", recall)\n",
    "                mlflow.log_metric(\"f1_score\", f1)\n",
    "                mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "                # Log hyperparameters for Random Forest and Gradient Boosting\n",
    "                if name in ['Random Forest', 'Gradient Boosting']:\n",
    "                    best_params = self.models[name].get_params()\n",
    "                    for param, value in best_params.items():\n",
    "                        mlflow.log_param(param, value)\n",
    "\n",
    "                # Save the model with a sanitized name\n",
    "                model_name = name.replace(\" \", \"_\").lower()\n",
    "\n",
    "                # Log the model to MLflow\n",
    "                if name in ['LSTM', 'CNN']:\n",
    "                    mlflow.keras.log_model(model, f\"{model_name}_model\")\n",
    "                else:\n",
    "                    mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "                # Register the model in the MLflow Model Registry\n",
    "                model_uri = f\"runs:/{mlflow.active_run().info.run_id}/{model_name}_model\"\n",
    "                mlflow.register_model(model_uri, f\"{model_name}\")\n",
    "\n",
    "                if roc_auc > best_score:\n",
    "                    best_score = roc_auc\n",
    "                    best_model = model\n",
    "                    best_model_name = name\n",
    "\n",
    "                self.performance_metrics[name] = {\n",
    "                    'Accuracy': accuracy,\n",
    "                    'Precision': precision,\n",
    "                    'Recall': recall,\n",
    "                    'F1 Score': f1,\n",
    "                    'ROC AUC': roc_auc\n",
    "                }\n",
    "                print(f\"{name} model trained and logged with MLflow\")\n",
    "\n",
    "        return best_model, best_model_name\n",
    "\n",
    "    def save_best_models(self, best_model, best_model_name, dataset_name):\n",
    "        \"\"\"Saves the best model to disk for later use.\"\"\"\n",
    "        sanitized_name = best_model_name.replace(' ', '_').lower()\n",
    "        joblib.dump(best_model, f\"../app/{sanitized_name}_{dataset_name}_best_model.pkl\")\n",
    "        print(f\"{best_model_name} best model saved.\")\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Returns the evaluation results for all models.\"\"\"\n",
    "        return self.performance_metrics, self.y_probs\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    from data_preparation import DataPreparation\n",
    "    import os\n",
    "\n",
    "    # Disable CUDA\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "    # Assuming df_creditcard is the DataFrame for the credit card dataset\n",
    "    credit_data = pd.read_csv('../data/creditcard.csv')  # Replace with your file path\n",
    "    _creditcard = DataPreparation(credit_data, target_column='Class')\n",
    "    _creditcard.train_test_split(test_size=0.2, random_state=42)\n",
    "\n",
    "    # Retrieving the train and test sets\n",
    "    X_train_cc, X_test_cc, y_train_cc, y_test_cc = _creditcard.get_train_test_data()\n",
    "\n",
    "    # Assuming df_fraud is the DataFrame for the fraud dataset\n",
    "    fraud_data = pd.read_csv('../data/fraud_data_processed.csv')  # Replace with your file path\n",
    "    _fraud = DataPreparation(fraud_data, target_column='class')              \n",
    "    _fraud.train_test_split(test_size=0.2, random_state=42)\n",
    "\n",
    "    # Retrieving the train and test sets\n",
    "    X_train_fd, X_test_fd, y_train_fd, y_test_fd = _fraud.get_train_test_data()\n",
    "\n",
    "    # Create and use the model pipeline\n",
    "    model_pipeline = ModelPipeline(X_train_fd, X_test_fd, y_train_fd, y_test_fd)\n",
    "\n",
    "    # Train and evaluate\n",
    "    best_model, best_model_name = model_pipeline.train_and_evaluate()\n",
    "\n",
    "    # Get results\n",
    "    results, predictions = model_pipeline.get_results()\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c4450-156b-47eb-9987-15aaef397df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
